<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Full-body Adaptive Grasp Planning with Differentiable">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Full-body Adaptive Grasp Planning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-2 publication-title">Differentiable Robot Neural Distance Function <p>for Adaptive Grasp Synthesis on</p> a Unified Robotic Arm-Hand System</h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.chen-yiting.com">Yiting Chen</a><sup>*,2</sup>,</span>
            <span class="author-block">
                <a href="https://people.epfl.ch/xiao.gao/?lang=en">Xiao Gao</a><sup>†,1</sup>,
            </span>
            <span class="author-block">
              <a href="https://people.epfl.ch/kunpeng.yao/?lang=en">Kunpeng Yao</a><sup>†,1</sup>,</span>

            <span class="author-block">
              <a href="https://people.epfl.ch/loic.niederhauser?lang=en">Loïc Niederhauser</a><sup>1</sup>,
            </span>
            <p>
            <span class="author-block">
              <a href="https://yaseminb.github.io/">Yasemin Bekiroglu</a><sup>2,3</sup>,
            </span>
            <span class="author-block">
              <a href="https://en.wikipedia.org/wiki/Aude_Billard">Aude Billard</a><sup>1</sup>
            </span>
            </p>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Work done during an internship at LASA, EPFL</span>
            <p>
            <span class="author-block"><sup>†</sup>Corresponding Authors</span>
            <p>
            <span class="author-block"><sup>1</sup>EPFL, </span>
            <span class="author-block"><sup>2</sup>Chalmers University of Technology</span>
            <span class="author-block"><sup>3</sup>University College London</span>
            </p>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://adaptive-grasping.github.io"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://adaptive-grasping.github.io"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              </p>
              <span class="author-block">The code and model will be released upon acceptance.</span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    
    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Supplementary Video</h2>
        <video id="matting-video" controls playsinline height="100%">
          <source src="./static/videos/supplementary_video.mp4"
                  type="video/mp4">
        </video>
      </div>
    </div> -->
    <!--/ Paper video. -->

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Grasping is a fundamental skill for robots to interact with their
environment. While grasp execution requires coordinated movement of the
hand and arm to achieve a collision-free and secure grip, many grasp
synthesis studies address arm and hand motion planning independently,
leading to potentially unreachable grasps in practical settings. The
challenge of determining integrated arm-hand configurations arises from
its computational complexity and high-dimensional nature. 
          </p>
          <p>
            We address
this challenge by presenting a novel differentiable robot neural
distance function. Our approach excels in capturing intricate geometry
across various joint configurations while preserving differentiability.
This innovative representation proves instrumental in efficiently
addressing downstream tasks with stringent contact constraints.
Leveraging this, we introduce an adaptive grasp synthesis framework
that exploits the full potential of the unified arm-hand system for
diverse grasping tasks. 
          </p>
          <!-- <p>
            Our neural joint space distance function achieves an 84.7% error reduction compared to baseline methods. We validated our approaches on a unified robotic arm-hand system that consists of a 7-DoF KUKA IIWA robot and a 16-DoF Allegro robotic hand. Results demonstrate that our approaches empower this high-DoF system to generate and execute various grasps that adapt to the size of the target objects.
          </p> -->
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Supplementary Video</h2>
        <video id="matting-video" controls playsinline height="100%">
          <source src="./static/videos/supplementary_video.mp4"
                  type="video/mp4">
        </video>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>

<div class="columns is-centered">
  <h2 class="title is-3">Robot Neural Distance Function</h2>
</div>
<section class="section">
  <div class="container is-max-desktop">
    <!-- <div class="columns is-centered"> -->

      <!-- Visual Effects. -->
      <!-- <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div> -->
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <!-- <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div> -->
    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">

        <!-- Interpolating. -->
        <h4 class="title is-4">Interpolating in Joint Space</h4>
        <div class="content has-text-justified">
          <p>
            Our robot neural distance function can generate smooth interpolation in the configuration space. 
            <p>
            The predicted distances with a value of 0 are visualized by the blue mesh. 
            The transparent space represents the area within 5cm from the surface of the robot.
            </p>
            <p>
            <b>Use the slider here to linearly interpolate between (0 to 90 degrees at the first joint) the left frame and the right
            frame</b>.
            </p>
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/>
        <!--/ Interpolating. -->

      </div>
      
    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>

<!-- <div class="columns is-centered">
  <h2 class="title is-3">Full-body Collision-free Grasp Planning</h2>
  
</div> -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Supplementary Video</h2>
        <video id="matting-video" controls playsinline height="100%">
          <source src="./static/videos/supplementary_video.mp4"
                  type="video/mp4">
        </video>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>



<footer class="footer">
  <div class="container">

    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This webpage is adapted from this <a
              href="https://github.com/nerfies/nerfies.github.io">template</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
